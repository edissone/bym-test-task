  input {
    jdbc {
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://test-bym-storage:5433/bym-storage"
    jdbc_user => "bmUSER"
    jdbc_password => "bmPWD!"
    statement => "SELECT order_id, order_amount, cast(order_items as text) as order_items, to_char(created_at, 'yyyy-MM-dd HH24:mm:ss') as created_at, to_char(updated_at, 'yyyy-MM-dd HH24:mm:ss') as updated_at FROM orders WHERE EXTRACT(epoch FROM updated_at) > :sql_last_value"
    tracking_column => "updated_at"
    use_column_value => true
    clean_run => true
    schedule => "*/1 * * * *"
    }
  }

  filter {
    json {
      source => "order_items"
      target => "order_items"
    }

    ruby {
      code => '
            order_items = []
            event.get("order_items").each do |item|
              nested_item = {
                "product_id" => item["product_id"],
                "product_name" => item["product_name"],
                "product_sku" => item["product_sku"],
                "product_price" => item["product_price"],
                "order_quantity" => item["order_quantity"]
              }
              order_items << nested_item
            end
            event.set("order_items", order_items)
          '
    }
    date {
      match => ["updated_at", "yyyy-MM-dd hh:mm:ss"]
      target => "updated_at"
    }
  }
    output {
      elasticsearch {
        hosts => ["http://test-bym-elastic:9201"]
        index => "orders"
        document_id => "%{order_id}"
    }
  }